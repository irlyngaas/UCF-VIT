# ---------------------------- TRAINER -------------------------------------------
trainer:
  max_epochs: 10000
  data_type: "bfloat16" #"float32" #
  gpu_type: "nvidia"
  checkpoint_path: "/lustre/fs0/scratch/ziabariak/checkpoint/xct/diffusion/base/full_2D/XCT_Conc_Synth/1200Vols/32x32x32/Pat200000_Dec0.9_ALLGPUs_4Nodes/N4_Adaptivelr0.00001_P1_BS256_ED1024_float32" #32x32x32/32Node_lr0.01_Patch8_batch1" # 
  checkpoint_filename: "XCT_Conc_base_Synth" #  "Breaker_AM_base" # "XCT_half_concrete_base" #  
  checkpoint_filename_for_loading: "XCT_Conc_base_Synth_0" #  "Breaker_AM_base_0" #  "XCT_half_concrete_base_0" #  xct_concrete_base_[EPOCH]
  inference_path: "/lustre/fs0/scratch/ziabariak/checkpoint/xct/diffusion/base/full_2D/XCT_Conc_Synth/1200Vols/32x32x32/Pat200000_Dec0.9_ALLGPUs_4Nodes/N4_Adaptivelr0.00001_P1_BS256_ED1024_float32/inference" #/32x32x32/32Node_lr0.01_Patch8_batch1/inference"

  resume_from_checkpoint: False

# ---------------------------- PARALLELISM -------------------------------------
parallelism:
  fsdp_size: 1
  simple_ddp_size: 32  #num of nodes * gpus
  tensor_par_size: 1
  seq_par_size: 1
  cpu_offloading: False

# ---------------------------- MODEL -------------------------------------------
model:
  lr: 0.00001
  beta_1: 0.9
  beta_2: 0.95
  weight_decay: 1e-5
  warmup_steps: 1000
  max_steps: 20000
  warmup_start_lr: 1e-8
  eta_min: 1e-8
  loss_fn: "MSE"
  use_grad_scaler: True

  net:
    init_args:
      default_vars: [
        "xct", 
      ]
      tile_size: [32,32,32] #[256, 256, 256]
      patch_size: 1 # 8
      embed_dim: 1024 #512 #1024
      depth: 8 # 10
      num_heads: 8
      decoder_embed_dim: 1024 # 576
      decoder_depth: 8
      decoder_num_heads: 16
      mlp_ratio: 4
      mlp_ratio_decoder: 4
      drop_path: 0.0
      drop_rate: 0.0  # 0.05 # 
      linear_decoder: True
      twoD: True
      use_varemb: False
      adaptive_patching: False
      fixed_length: 196
      separate_channels: False
      num_time_steps: 1000

# ---------------------------- DATA -------------------------------------------
data:
  dataset: "xct"
  dict_root_dirs: {
    # 'xct1': "/lustre/fs0/scratch/ziabariak/XCT_Concrete_32x32_Z00730/",
    'xct1': "/lustre/fs0/scratch/ziabariak/data_LDRD/XCT_NCT_Synth/Downsampled_128x128_128_beforeCrop/XCT_Concrete_32x32x32_Synth_artificallyStandardized/",
    #"/lustre/fs0/scratch/lyngaasir/DiffusiveINR_Data/XCT_Concrete_Z00730_650Files", #599 #'/lustre/fs0/scratch/ziabariak/XCT_Concrete_32x32x32_Z00730', # 
    }
  dict_start_idx: {
    'xct1': 0,
  }
  dict_end_idx: {
    'xct1': 1,
  }
  dict_buffer_sizes: {
    'xct1': 100,
  }
  num_channels_used: {
    'xct1': 1,
  }
  dict_in_variables: {
    'xct1': [
     "xct", 
    ],
  }
  batch_size: 256
  num_workers: 1
  pin_memory: False
  single_channel: False
  tile_overlap: 0.0
  use_all_data: False

# ---------------------------- LOAD BALANCING -------------------------------------------
load_balancing:
  auto_load_balancing: True
  batches_per_rank_epoch: {
  'xct1': 600,
  }
  dataset_group_list: '16' #'1:3:75:1:8:4' # '2:1' # '16' # 75:
