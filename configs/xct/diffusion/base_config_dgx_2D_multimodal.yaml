# ---------------------------- TRAINER -------------------------------------------
trainer:
  max_epochs: 20000
  data_type: "float32" #"bfloat16"
  gpu_type: "nvidia"
  checkpoint_path: "/lustre/fs0/scratch/ziabariak/checkpoint/xct/diffusion/base/full_2D_standardized/XCT_NCT_All/256x256x256/Pat2000_Dec0.9/N8_Adaptlr0.008_P16_BS1024_ED1024" #32x32x32/32Node_lr0.01_Patch8_batch1" # 
  checkpoint_filename: "XCT_NCT_base" #   "Breaker_AM_base" # "XCT_half_concrete_base" #  
  checkpoint_filename_for_loading: "XCT_NCT_base_0" # "Breaker_AM_base_0" #   "XCT_half_concrete_base_0" #  xct_concrete_base_[EPOCH]
  inference_path: "/lustre/fs0/scratch/ziabariak/checkpoint/xct/diffusion/base/full_2D_standardized/XCT_NCT_All/256x256x256/Pat2000_Dec0.9/N8_Adaptlr0.008_P16_BS1024_ED1024/inference" #/32x32x32/32Node_lr0.01_Patch8_batch1/inference"

  resume_from_checkpoint: False

# ---------------------------- PARALLELISM -------------------------------------
parallelism:
  fsdp_size: 1
  simple_ddp_size: 64  #num of nodes * gpus
  tensor_par_size: 1
  seq_par_size: 1
  cpu_offloading: False

# ---------------------------- MODEL -------------------------------------------
model:
  lr: 0.008
  beta_1: 0.9
  beta_2: 0.95
  weight_decay: 1e-5
  warmup_steps: 1000
  max_steps: 20000
  warmup_start_lr: 1e-8
  eta_min: 1e-8
  loss_fn: "MSE"
  use_grad_scaler: False #True

  net:
    init_args:
      default_vars: [
        "xct", 
        "nct",
        "xctC",
        "xctT",
        "xctB",
        "xctA",
      ]
      tile_size: [256, 256, 256]
      patch_size: 16
      embed_dim: 1024
      depth: 8
      num_heads: 8
      decoder_embed_dim: 1024
      decoder_depth: 8
      decoder_num_heads: 16
      mlp_ratio: 6
      mlp_ratio_decoder: 4
      drop_path: 0.1
      drop_rate: 0.0
      linear_decoder: True
      twoD: True
      use_varemb: False
      adaptive_patching: False
      fixed_length: 196
      separate_channels: False
      num_time_steps: 1000

# ---------------------------- DATA -------------------------------------------
data:
  dataset: "xct"
  dict_root_dirs: {
    'xct1': '/lustre/fs0/scratch/lyngaasir/DiffusiveINR_Data/XCT_Concrete_Z00730_650Files_standardized', #600 #'/lustre/fs0/scratch/ziabariak/XCT_Concrete_32x32x32_Z00730', # 
    'nct1': "/lustre/fs0/scratch/ziabariak/data_LDRD/NeutronCT_Concrete_256x256x256_standardized/", # 1539
    'xct2': "/lustre/fs0/scratch/ziabariak/data_LDRD/XCT_Concrete_256x256_standardized", #16800
    'xct3': "/lustre/fs0/scratch/ziabariak/data_LDRD/TRISO_Data/Triso_Data_256x256x256_standardized", #680
    'xct4': "/lustre/fs0/scratch/ziabariak/data_LDRD/Breaker_data/256x256x256_standardized", # 5120
    'xct5': "/lustre/fs0/scratch/ziabariak/data_LDRD/AM_ScattCorrected_data/AM_ScatterCorrected_Data_256x256x256_standardized", # 1022
  }
  dict_start_idx: {
    'xct1': 0,
    'nct1': 0,
    'xct2': 0,
    'xct3': 0,
    'xct4': 0,
    'xct5': 0,
  }
  dict_end_idx: {
    'xct1': 1,
    'nct1': 1,
    'xct2': 0.143,
    'xct3': 1,
    'xct4': 0.5,
    'xct5': 1,
  }
  dict_buffer_sizes: {
    'xct1': 200,
    'nct1': 200,
    'xct2': 200,
    'xct3': 200,
    'xct4': 200,
    'xct5': 200,
  }
  num_channels_used: {
    'xct1': 1,
    'nct1': 1,
    'xct2': 1,
    'xct3': 1,
    'xct4': 1,
    'xct5': 1,
  }
  dict_in_variables: {
    'xct1': [
     "xct", 
    ],
    'nct1': [
     "nct", 
    ],
    'xct2': [
     "xctC", 
    ],
    'xct3': [
     "xctT", 
    ],
    'xct4': [
     "xctB", 
    ],
    'xct5': [
     "xctA", 
    ],
  }
  batch_size: 512
  num_workers: 1
  pin_memory: False
  single_channel: False
  tile_overlap: 0.0
  use_all_data: False

# ---------------------------- LOAD BALANCING -------------------------------------------
load_balancing:
  auto_load_balancing: True
  batches_per_rank_epoch: {
  'xct1': 600,
  'nct1': 1200,
  'xct2': 5000,
  'xct3': 600,
  'xct4': 2000,
  'xct5': 1000,
  }
  dataset_group_list: '2:1' # '1:3:75:1:8:4' # '16' # 75:
