# ---------------------------- TRAINER -------------------------------------------
trainer:
  max_epochs: 100  # Reduced epochs for fast testing
  data_type: "float32"
  checkpoint_path: "../../checkpoint/catsdogs/classification/quanto_8bit"
  checkpoint_filename: "multi_last"
  checkpoint_filename_for_loading: "multi_last_odd" #multi_last_odd or multi_last_even

  resume_from_checkpoint: False

# ---------------------------- PARALLELISM -------------------------------------
parallelism:
  fsdp_size: 1
  simple_ddp_size: 8
  tensor_par_size: 1
  seq_par_size: 1

# ---------------------------- MODEL -------------------------------------------
model:
  lr: 0.0001
  beta_1: 0.9
  beta_2: 0.95
  weight_decay: 1e-5
  warmup_steps: 100  # Reduced for fast testing
  max_steps: 2000    # Reduced for fast testing
  warmup_start_lr: 1e-8
  eta_min: 1e-8

  net:
    init_args:
      default_vars: [
        "red",
        "green",
        "blue",
      ]
      tile_size: [256, 256]
      patch_size: 16
      embed_dim: 768
      depth: 12
      num_heads: 12
      mlp_ratio: 4
      drop_path: 0.0
      drop_rate: 0.0
      twoD: True
      use_varemb: False
      adaptive_patching: False
      fixed_length: 196
      separate_channels: False
      use_adaptive_pos_emb: True

# ---------------------------- DATA -------------------------------------------
data:
  dataset: "catsdogs"
  dict_root_dirs: {
    'catsdogs': '/lustre/orion/stf006/world-shared/irl1/CatsDogs/train',
  }
  dict_in_variables: {
    'catsdogs': [
     "red", 
     "green", 
     "blue", 
    ],
  }
  batch_size: 64  # Increased batch size for testing
  num_workers: 1
  pin_memory: False
  num_classes: 2

# ---------------------------- QUANTO QUANTIZATION -------------------------------------------
# QUANTO 8-BIT QUANTIZATION CONFIG FOR CATSDOGS TESTING
quantization:
  enabled: true  # ENABLE QUANTO 8-BIT QUANTIZATION
  bits: 8         # Start with 8-bit (50% memory reduction)
  quantize_weights: true
  quantize_activations: false  # Disable for speed - only quantize weights
  calibration_samples: 10      # Minimal calibration for speed
  quantize_layers: ["linear"]  # Only quantize linear layers for speed
  exclude_layers: ["cls_token", "pos_embed"]  # Preserve critical embeddings
  
  # Performance optimizations
  rocm_optimizations: false   # Disable for speed
  mi250x_kernels: false      # Disable for speed
  performance_mode: "fast"    # Fast mode instead of extreme_scale
  profile_quantization: false # Disable profiling for speed
